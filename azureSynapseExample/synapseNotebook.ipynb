{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "storage_account_name = \"<YOUR_STORAGE_ACCOUNT_NAME>\"\n",
    "container_name = \"<YOUR_WORKSPACE_NAME>\"\n",
    "source_path = f\"abfss://{storage_account_name}@{container_name}.dfs.core.windows.net/synapseExample/00_source/\"\n",
    "bronze_path = f\"abfss://{storage_account_name}@{container_name}.dfs.core.windows.net/synapseExample/01_bronze/\"\n",
    "silver_path = f\"abfss://{storage_account_name}@{container_name}.dfs.core.windows.net/synapseExample/02_silver/\"\n",
    "gold_path = f\"abfss://{storage_account_name}@{container_name}.dfs.core.windows.net/synapseExample/03_gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source data\n",
    "customers_df = spark.read.csv(f\"{source_path}customers.csv\", header=True, inferSchema=True)\n",
    "products_df = spark.read.csv(f\"{source_path}products.csv\", header=True, inferSchema=True)\n",
    "orders_df = spark.read.csv(f\"{source_path}orders.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each dataframe to bronze folder in Parquet format\n",
    "customers_df.write.mode(\"overwrite\").parquet(f\"{bronze_path}customers/\")\n",
    "products_df.write.mode(\"overwrite\").parquet(f\"{bronze_path}products/\")\n",
    "orders_df.write.mode(\"overwrite\").parquet(f\"{bronze_path}orders/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example querying using SQL syntax\n",
    "customers_df.createOrReplaceTempView(\"Customers\")\n",
    "result = spark.sql(\"SELECT * FROM Customers where Email like 'ant%'\")\n",
    "result.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform from Bronze to Silver\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load data from Bronze layer\n",
    "customers_bronze_df = spark.read.parquet(f\"{bronze_path}customers/\")\n",
    "orders_bronze_df = spark.read.parquet(f\"{bronze_path}orders/\")\n",
    "products_bronze_df = spark.read.parquet(f\"{bronze_path}products/\")\n",
    "\n",
    "\n",
    "# Step 1: Clean and Standardize Customers Data\n",
    "# Remove duplicates based on CustomerID and standardize phone numbers and emails\n",
    "customers_silver_df = (\n",
    "    customers_bronze_df\n",
    "    .dropDuplicates([\"CustomerID\"])\n",
    "    .filter(F.col(\"Email\").contains(\"@\"))  # Basic email validation\n",
    "    .withColumn(\"PhoneNumber\", F.regexp_replace(\"PhoneNumber\", r\"[^\\d]\", \"\"))  # Remove non-numeric characters\n",
    ")\n",
    "\n",
    "# Step 2: Clean and Standardize Orders Data\n",
    "# Remove any records with null OrderID, CustomerID, ProductID, and ensure valid quantity and total amount\n",
    "orders_silver_df = (\n",
    "    orders_bronze_df\n",
    "    .dropDuplicates([\"OrderID\"])\n",
    "    .filter(F.col(\"CustomerID\").isNotNull() & F.col(\"ProductID\").isNotNull())\n",
    "    .filter((F.col(\"Quantity\") > 0) & (F.col(\"TotalAmount\") > 0))  # Ensure valid values\n",
    "    .withColumn(\"OrderDate\", F.to_date(\"OrderDate\"))  # Standardize date format\n",
    ")\n",
    "\n",
    "# Step 3: Clean and Standardize Products Data\n",
    "# Remove duplicates based on ProductID and ensure positive stock and price\n",
    "products_silver_df = (\n",
    "    products_bronze_df\n",
    "    .dropDuplicates([\"ProductID\"])\n",
    "    .filter(F.col(\"Price\") > 0)  # Ensure positive price\n",
    "    .filter(F.col(\"Stock\") >= 0)  # Stock should not be negative\n",
    ")\n",
    "\n",
    "# Write data to Silver layer\n",
    "customers_silver_df.write.mode(\"overwrite\").parquet(f\"{silver_path}customers/\")\n",
    "orders_silver_df.write.mode(\"overwrite\").parquet(f\"{silver_path}orders/\")\n",
    "products_silver_df.write.mode(\"overwrite\").parquet(f\"{silver_path}products/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to Gold Layer\n",
    "\n",
    "# Load data from Silver layer\n",
    "customers_silver_df = spark.read.parquet(f\"{silver_path}customers/\")\n",
    "orders_silver_df = spark.read.parquet(f\"{silver_path}orders/\")\n",
    "products_silver_df = spark.read.parquet(f\"{silver_path}products/\")\n",
    "\n",
    "# Step 1: Enrich Orders with Customer and Product Information\n",
    "# Join orders with customers and products to enrich order data\n",
    "orders_enriched_df = (\n",
    "    orders_silver_df\n",
    "    .join(customers_silver_df, on=\"CustomerID\", how=\"left\")\n",
    "    .join(products_silver_df, on=\"ProductID\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Step 2: Create an Aggregated Customer Orders Summary\n",
    "# Calculate total orders, total quantity, and total amount spent per customer\n",
    "customer_summary_df = (\n",
    "    orders_enriched_df\n",
    "    .groupBy(\"CustomerID\", \"CustomerName\", \"Email\", \"Country\")\n",
    "    .agg(\n",
    "        F.count(\"OrderID\").alias(\"TotalOrders\"),\n",
    "        F.sum(\"Quantity\").alias(\"TotalQuantityPurchased\"),\n",
    "        F.sum(\"TotalAmount\").alias(\"TotalAmountSpent\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 3: Create a Product Sales Summary\n",
    "# Calculate total quantity sold and total revenue per product\n",
    "product_summary_df = (\n",
    "    orders_enriched_df\n",
    "    .groupBy(\"ProductID\", \"ProductName\", \"Category\")\n",
    "    .agg(\n",
    "        F.sum(\"Quantity\").alias(\"TotalQuantitySold\"),\n",
    "        F.sum(\"TotalAmount\").alias(\"TotalRevenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 4: Create a Daily Sales Summary\n",
    "# Calculate total orders, quantity, and revenue per day\n",
    "daily_sales_summary_df = (\n",
    "    orders_enriched_df\n",
    "    .groupBy(\"OrderDate\")\n",
    "    .agg(\n",
    "        F.count(\"OrderID\").alias(\"TotalOrders\"),\n",
    "        F.sum(\"Quantity\").alias(\"TotalQuantitySold\"),\n",
    "        F.sum(\"TotalAmount\").alias(\"TotalRevenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 5: Write Data to Gold Layer\n",
    "customer_summary_df.write.mode(\"overwrite\").parquet(f\"{gold_path}customer_summary/\")\n",
    "product_summary_df.write.mode(\"overwrite\").parquet(f\"{gold_path}product_summary/\")\n",
    "daily_sales_summary_df.write.mode(\"overwrite\").parquet(f\"{gold_path}daily_sales_summary/\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
